<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!--
  <script src="./resources/jsapi" type="text/javascript"></script>
  <script type="text/javascript" async>google.load("jquery", "1.3.2");</script>
 -->
    <style type="text/css">
        @font-face {
            font-family: 'Avenir Book';
            src: url("./fonts/Avenir_Book.ttf"); /* File to be stored at your site */
        }
    body {
    font-family: "Avenir Book", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:14px;
    margin-left: auto;
    margin-right: auto;
    width: 900px;
  }
  h1 {
    font-weight:300;
  }
  h2 {
    font-weight:300;
  }

  p {
    font-weight:300;
    line-height: 1.4;
  }

  code {
    font-size: 0.8rem;
    margin: 0 0.2rem;
    padding: 0.5rem 0.8rem;
    white-space: nowrap;
    background: #efefef;
    border: 1px solid #d3d3d3;
    color: #000000;
    border-radius: 3px;
  }

  pre > code {
    display: block;
    white-space: pre;
    line-height: 1.5;
    padding: 0;
    margin: 0;
  }

  pre.prettyprint > code {
    border: none;
  }


  .container {
        display: flex;
        align-items: center;
        justify-content: center
  }
  .image {
        flex-basis: 40%
  }
  .text {
        padding-left: 20px;
        padding-right: 20px;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;

  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>
	<title>Towards Uncovering the Intrinsic Data Structures for Unsupervised Domain Adaptation using Structurally Regularized Deep Clustering</title>
</head>

<body>
<br>
<span style="font-size:36px">
    <div style="text-align: center;">
        Towards Uncovering the Intrinsic Data Structures for Unsupervised Domain Adaptation using Structurally Regularized Deep Clustering
    </div>
</span>
<br>
<br>
<br>
<table align="center" width="700px">
    <tr>
        <td align="center" width="120px">
            <div style="text-align: center;">
                <span style="font-size:16px"><a href="https://huitangtang.github.io/">Hui Tang</a><sup>1</sup></span>
            </div>
        </td>
	    
        <td align="center" width="120px">
            <div style="text-align: center;">
                <span style="font-size:16px"><a href="https://xiatian-zhu.github.io/">Xiatian Zhu</a><sup>2</sup></span>
            </div>
        </td>
      
        <td align="center" width="120px">
            <div style="text-align: center;">
                <span style="font-size:16px"><a href="https://scholar.google.com/citations?user=pbNCoTwAAAAJ">Ke Chen</a><sup>1</sup></span>
            </div>
        </td>
        
        <td align="center" width="120px">
            <div style="text-align: center;">
                <span style="font-size:16px">
                    <a href="http://kuijia.site/">Kui Jia</a>
<!--                    <sup><img class="round" style="width:20px" src="./resources/corresponding_fig.png">3</sup>-->
                    <sup>&#9993, 1</sup>
                </span>
            </div>
        </td>
	    
        <td align="center" width="120px">
            <div style="text-align: center;">
                <span style="font-size:16px"><a href="https://orcid.org/0000-0001-5451-7230">C. L. Philip Chen</a><sup>1</sup></span>
            </div>
        </td>
    </tr>
</table>

<br>
	
<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="300px">
            <center>
                <span style="font-size:16px">South China University of Technology<sup>1</sup></span>
            </center>
        </td>
        <td align="center" width="300px">
            <center>
                <span style="font-size:16px">University of Surrey<sup>2</sup></span>
            </center>
        </td>
    </tr>
    </tbody>
</table>


<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="300px">
            <center>
                <span style="font-size:16px"><sup>&#9993</sup>Corresponding author</span>
            </center>
        </td>
    </tr>
    </tbody>
</table>

<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:20px">
                    Code
                    <a href="https://github.com/huitangtang/H-SRDC">[GitHub]</a>
                </span>
            </div>
        </td>

        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:20px">
                    Paper
                    <a href="https://arxiv.org/pdf/2012.04280">[arXiv]</a>
                </span>
            </div>
        </td>

        <td align="center" width="200px">
            <center>
                <span style="font-size:20px">
                    Cite <a href="resources/cite.txt">[BibTeX]</a>
                </span>
            </center>
        </td>
    </tr>
    </tbody>
</table>
<br>
<hr>

<div style="text-align: center;">
    <h2>Teaser</h2>
</div>

<p style="text-align:justify; text-justify:inter-ideograph;">
<table>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/H-SRDC.png" width="900px">
            </div>
        </td>
    </tr>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		We are motivated by a Unsupervised domain adaptation (UDA) assumption of structural similarity across domains, 
		and propose to directly uncover the intrinsic target discrimination via constrained clustering, 
		where we constrain the clustering solutions using structural source regularization that hinges on the very same assumption. 
		Technically, we propose a hybrid model of Structurally Regularized Deep Clustering, 
		which integrates the regularized discriminative clustering of target data with a generative one, and we thus term our method as H-SRDC.
            </p>
        </td>
    </tr>
</table>


<br>
<hr>
<div style="text-align: center;">
    <h2>Abstract</h2>
</div>

<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Unsupervised domain adaptation (UDA) is to learn classification models that make predictions for unlabeled data on a target domain, 
		given labeled data on a source domain whose distribution diverges from the target one. 
		Mainstream UDA methods strive to learn domain-aligned features such that 
		classifiers trained on the source features can be readily applied to the target ones. 
		Although impressive results have been achieved, these methods have a potential risk of damaging the <i>intrinsic</i> data structures of target discrimination, 
		raising an issue of generalization particularly for UDA tasks in an inductive setting. 
		To address this issue, we are motivated by a UDA assumption of <i>structural similarity</i> across domains, 
		and propose to directly uncover the intrinsic target discrimination via constrained clustering, 
		where we constrain the clustering solutions using structural source regularization that hinges on the very same assumption. 
		Technically, we propose a hybrid model of <i>Structurally Regularized Deep Clustering</i>, 
		which integrates the regularized discriminative clustering of target data with a generative one, 
		and we thus term our method as H-SRDC. 
		Our hybrid model is based on a deep clustering framework that minimizes the Kullback-Leibler divergence between the distribution of network prediction and an auxiliary one, 
		where we impose structural regularization by learning domain-shared classifier and cluster centroids. 
		By enriching the structural similarity assumption, we are able to extend H-SRDC for a pixel-level UDA task of semantic segmentation. 
		We conduct extensive experiments on seven UDA benchmarks of image classification and semantic segmentation. 
		With no explicit feature alignment, our proposed H-SRDC outperforms all the existing methods under both the inductive and transductive settings.
            </p>
        </td>
    </tr>
</table>

<!-- This is the begining of next edition!!!
  
<br>
<hr>
<div style="text-align: center;">
    <h2>Background & Motivation</h2>
</div>

<table>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/UDA.png" width="600px">
            </div>
        </td>
    </tr>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		The success of deep learning relies on a large amount of training data. 
		However, collecting and annotating data for all domains and tasks is extremely expensive and time-consuming. 
		We can utilize data from a label-rich source domain to solve the task on a label-scarce target domain. 
		But there is a distribution discrepancy between the source and target data. 
		So the model trained on source data cannot be readily applied to target data. 
		How to address this issue? Unsupervised domain adaptation (UDA)!
            </p>
        </td>
    </tr>
    <br>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/strategy.png" width="600px">
            </div>
        </td>
    </tr>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		(a) Illustration of the assumption of structural domain similarity, including two concepts: domain-wise discrimination and class-wise closeness. 
		The orange line denotes the classifier trained on the labeled source data and the green	one denotes the classifier trained on the labeled target data, i.e. the oracle target classifier. 
		(b) Illustration of damaging intrinsic structures of data discrimination on the target domain by the existing transferring strategy. 
		The dashed line denotes the source classifier adapting to the damaged discrimination of target data, which has a sub-optimal generalization. 
		(c) Illustration of our proposed uncovering strategy. Discriminative target clustering with structural source regularization uncovers intrinsic target discrimination. 
		<br>
		<br>
		Mainstream UDA methods take the transferring strategy of learning aligned features across domains, 
		which has a potential risk of damaging the intrinsic discrimination of target data, resulting in a sub-optimal generalization. 
		Based on our assumed structural domain similarity, we directly uncover the intrinsic target discrimination via discriminative clustering of target data 
		and constrain the clustering solutions using structural source regularization, leading to an adapted classifier closer to the oracle target classifier. 
            </p>
        </td>
    </tr>
</table>

<br>
<hr>
<div style="text-align: center;">
    <h2>Highlights</h2>
</div>

<div style="text-align: center;">
    <h3>Deep Discriminative Target Clustering</h3>
</div>
	
<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		We propose to use deep discriminative target clustering in the output space and feature space at the same time. This is a new dual clustering framework. 
		The clustering algorithm obtains pseudo labels of target data to supervise the model training by minimizing an objective of two terms. 
		The first term is the KL divergence between the network prediction label distribution and the introduced auxiliary distribution; 
		the second term is a regularization of cluster size balance. 
		<br>
		<br>
		Here, category prediction probability modeling in feature space is based on Euclidean distance from instance to learnable cluster centers. 
		The clustering behavior in feature space can not only further reveal the inherent differences between target data, 
		but also act as the constraint of clustering in output space to maintain different cluster centers and avoid mode collapse.
            </p>
        </td>
    </tr>
</table>

<div style="text-align: center;">
    <h3>Structural Source Regularization</h3>
</div>
	
<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Based on the structural similarity between the source and target domains indicated by the UDA assumption, 
		we propose the structural source regularization â€” replacing the auxiliary distribution with truth label distribution, 
		and using the labeled source data to train the same classifier network layers, namely joint network training. 
		<br>
		<br>
		In addition, we propose a soft selection strategy for source samples, 
		which weights the source samples according to their importance to the target domain. 
		The concept of class-wise closeness in the assumption of structural domain similarity implies that 
		different source instances may have different regularization effects; 
		accordingly, they can be weighted based on distances to corresponding target clusters. 
            </p>
        </td>
    </tr>
</table>

<div style="text-align: center;">
    <h3>Training Algorithm</h3>
</div>
	

<div style="text-align: center;">
	<img src="resources/alg.png" width="500px">
</div>


<br>
<hr>
<div style="text-align: center;">
    <h2>Experiments</h2>
</div>

<div style="text-align: center;">
    <h3>Ablation Study and Learning Analysis</h3>
</div>

<table>
    <tr>
        <td>
            <p>
                <b>
                    R1: Ablation Study
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		In the following table, we can observe that when any one of our designed components is removed, the performance degrades, 
		verifying that (1) both feature discrimination and structural source regularization are effective for improving target clustering; 
		(2) the proposed soft source sample selection scheme leads to better regularization. 
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab1.png" width="700px">
            </div>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R2: Source Refinement
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                In the following figure, we can observe that the source images with a canonical viewpoint have the higher weights than those with top-down, bottom-up, and side viewpoints, 
		which is intuitive since all target images are shown only from a canonical viewpoint. 
		The observation affirms the rationality of our proposed soft source sample selection scheme.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/select.png" width="500px">
            </div>
	    <p style="text-align:center;">
		The images on the left are randomly sampled from the target domain Amazon and 
		those on the right are the top-ranked (the 3<sup>rd</sup> column) and bottom-ranked (the 4<sup>th</sup> column) samples from the source domain Webcam for three classes. 
		Note that the red numbers are the computed source weights. 
	    </p>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R3: Comparison under Inductive UDA Setting
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		In the following table, we can see that our proposed uncovering strategy SRDC achieves closer results to Oracle Model, 
		verifying the motivation of this work and the efficacy of our proposed SRDC.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab2.png" width="500px">
            </div>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R4: Feature Visualization
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                In the following figure, We can qualitatively observe that compared to Source Model, 
		the target domain features can be much better discriminated by SRDC, 
		which is based on data clustering to uncover the discriminative data structures.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tsne.png" width="900px">
            </div>
	    <p style="text-align:center;">
		The t-SNE visualization of embedded features on the target domain.
	    </p>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R5: Confusion Matrix
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                In the following figure,  we can observe quantitative improvements from Source Model to SRDC, further confirming the advantages of SRDC.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/confusion_matrix.png" width="900px">
            </div>
	    <p style="text-align:center;">
		The confusion matrix on the target domain.
	    </p>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R6: Convergence Performance
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                In the following figure, We can observe that SRDC enjoys faster and smoother convergence performance than Source Model.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/convergence.png" width="500px">
            </div>
        </td>
    </tr>
</table>


<br>
<div style="text-align: center;">
    <h3>Comparison with SOTA</h3>
</div>

<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		 Notably, with no explicit domain alignment, our proposed SRDC outperforms all existing methods on three UDA benchmark datasets.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab3.png" width="900px">
            </div>
	    <p style="text-align:center;">
		Results (%) on Office-31 (ResNet-50).
	    </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab4.png" width="900px">
            </div>
	    <p style="text-align:center;">
		Results (%) on ImageCLEF-DA (ResNet-50).
	    </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab5.png" width="900px">
            </div>
	    <p style="text-align:center;">
		Results (%) on Office-Home (ResNet-50).
	    </p>
        </td>
    </tr>
</table>

This is the end of next edition!!! -->
	
<br>
<hr>

<div style="text-align: center;">
    <h2>BibTeX</h2>
</div>
      <pre>
  	<code>
@article{tang2021towards,
  author={Tang, Hui and Zhu, Xiatian and Chen, Ke and Jia, Kui and Chen, C. L. Philip},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Towards Uncovering the Intrinsic Data Structures for Unsupervised Domain Adaptation Using Structurally Regularized Deep Clustering}, 
  year={2022},
  volume={44},
  number={10},
  pages={6517-6533},
  doi={10.1109/TPAMI.2021.3087830}
}
  	</code>
      </pre>
	
<br>
<hr>

<div style="text-align: center;">
    <h2>Acknowledgements</h2>
</div>
      <p>
	      Based on a template by <a href="https://kyanchen.github.io/OvarNet/">Keyan Chen</a>.
      </p>

<br>
<br>
<br>

</body>
</html>
